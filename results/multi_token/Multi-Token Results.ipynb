{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Token Experiments\n",
    "\n",
    "The goal here is to run some quick + preliminary experiments on controlling \n",
    "multi-token generation. \n",
    " * $|x_0|$ = `question_len` $\\in$ [4, 8, 16, 32]\n",
    " * $|y|$ = `answer_len` $\\in$ [2, 3, 4]\n",
    " * $|u| = k$ = greedy `1, 2, 3`, gcg `4, 8, 16, 32, 64`\n",
    "     - GCG num_iters should be longer (3x)\n",
    "\n",
    "We have 12 different question-answer length combinations. Let's assume each \n",
    "control experiment takes ~10 minutes. We have 16 hours to run these on 8 A100's, \n",
    "which means we can run (16 h/A100) * (8 A100) * (6 exp/h) = 768 experiments. \n",
    "\n",
    "768/12 = 64 experiments per question/answer length. \n",
    "\n",
    "**Generate the dataset**: \n",
    "```bash\n",
    "python3 scripts/make_control_dataset.py \\\n",
    "    --out_file results/multi_token/mt_falcon_dataset_768.csv \\\n",
    "    --model_name tiiuae/falcon-7b \\\n",
    "    --question_lens 4 8 16 32 \\\n",
    "    --answer_lens 2 3 4 \\\n",
    "    --num_examples_per_qa_size 64\n",
    "```\n",
    "\n",
    "**Run the experiments**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
